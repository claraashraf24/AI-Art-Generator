{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO9Cxt4bn7Nw",
        "outputId": "b0008b23-6e3f-4365-d764-9e77f9541bb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4rIl5pcpmVc",
        "outputId": "6f6732de-016f-4573-9ef2-76a0c705e9db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
        "trainset = torchvision.datasets.CIFAR10(root= '/data', train = True, download= True, transform= transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size= 64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3mPSi8vqdj5"
      },
      "outputs": [],
      "source": [
        "#normalize pixel values\n",
        "x_train = x_train.astype('float32')\n",
        "x_train = (x_train - 127.5)/127.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEJCskMBq2C7"
      },
      "outputs": [],
      "source": [
        "#reshape data\n",
        "x_train = x_train.reshape(-1,32,32,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qed8sZiGrMm8"
      },
      "source": [
        "**Build the GAN architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mz2TCfKrOP9"
      },
      "outputs": [],
      "source": [
        "#define the generator\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "def build_generator():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Dense(8*8*256, use_bias=False, input_shape=(100,)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Reshape((8, 8, 256)))\n",
        "  model.add(layers.Conv2DTranspose(128,(5,5), strides=(2,2), padding='same', use_bias=False))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(64,(5,5), strides=(2,2), padding='same', use_bias=False))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(3, (5,5), strides=(1,1), padding='same', use_bias=False, activation='tanh'))\n",
        "  return model\n",
        "\n",
        "generator = build_generator()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezaQil1AtFnx",
        "outputId": "6075ffbf-4353-4d97-9eb0-d5377e480638"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "#define the discriminator\n",
        "def build_discriminator():\n",
        "  model= tf.keras.Sequential()\n",
        "  model.add(layers.Conv2D(64,(5,5), strides=(2,2), padding='same', input_shape=[32,32,3]))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv2D(128, (5,5), strides=(2,2), padding='same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1))\n",
        "  return model\n",
        "\n",
        "discriminator = build_discriminator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJ9VSl6yt49I"
      },
      "outputs": [],
      "source": [
        "#compile the models\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  total_loss = real_loss + fake_loss\n",
        "  return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4skV580uzBu"
      },
      "source": [
        "**Implement the training loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcAcgCUbu2MY"
      },
      "outputs": [],
      "source": [
        "#set training parameters\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 256\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6j5M6d_fu_ZS"
      },
      "outputs": [],
      "source": [
        "#prepare the dataset\n",
        "BUFFER_SIZE = x_train.shape[0]\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjxlLtn0vOrP"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Pp58R7wxFT"
      },
      "outputs": [],
      "source": [
        "#training loop function\n",
        "import time\n",
        "from IPython import display\n",
        "\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "\n",
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator, epoch+1, seed)\n",
        "\n",
        "    print(f'Time for epoch {epoch + 1} is {time.time()-start:.2f} sec')\n",
        "\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator, epochs, seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9pEXj6BxjJq"
      },
      "outputs": [],
      "source": [
        "#visualization function\n",
        "#generate and save images\n",
        "import matplotlib.pyplot as plt\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  predictions = model(test_input, training=False)\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "    plt.subplot(4,4, i+1)\n",
        "    plt.imshow((predictions[i]* 127.5 + 127.5).numpy().astype(\"uint8\"))\n",
        "    plt.axis('off')\n",
        "\n",
        "  plt.savefig(f'image_at_epoch_{epoch:04d}.png')\n",
        "  plt.show\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kJAJ-rZyk77"
      },
      "source": [
        "**Start Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXYep7odynjZ",
        "outputId": "eaeb348e-920c-4c1d-edd0-a2419d2e4d2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 1 is 1094.13 sec\n",
            "Time for epoch 2 is 1090.07 sec\n",
            "Time for epoch 3 is 1084.33 sec\n"
          ]
        }
      ],
      "source": [
        "#run the training loop\n",
        "train(train_dataset, EPOCHS)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}